{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym\n",
      "  Downloading https://files.pythonhosted.org/packages/1a/db/816fd52c0c196b6799e89d1f65b6c74fead2707cf7d447f3f354edfa7a44/gym-0.18.3.tar.gz (1.6MB)\n",
      "Requirement already satisfied: scipy in d:\\anaconda\\lib\\site-packages (from gym) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.10.4 in d:\\anaconda\\lib\\site-packages (from gym) (1.16.2)\n",
      "Collecting pyglet<=1.5.15,>=1.4.0 (from gym)\n",
      "  Downloading https://files.pythonhosted.org/packages/81/5e/aef9e460989e4b832215d5fcee3ea9b0629e9bce8607284d9c1021b6a251/pyglet-1.5.15-py3-none-any.whl (1.1MB)\n",
      "Requirement already satisfied: Pillow<=8.2.0 in d:\\anaconda\\lib\\site-packages (from gym) (5.4.1)\n",
      "Collecting cloudpickle<1.7.0,>=1.2.0 (from gym)\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/e3/898487e5dbeb612054cf2e0c188463acb358167fef749c53c8bb8918cea1/cloudpickle-1.6.0-py3-none-any.whl\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (setup.py): started\n",
      "  Building wheel for gym (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\saty\\AppData\\Local\\pip\\Cache\\wheels\\93\\c2\\4c\\2b4c9b85119994837c08315c9415d71008325b7004d385b418\n",
      "Successfully built gym\n",
      "Installing collected packages: pyglet, cloudpickle, gym\n",
      "  Found existing installation: cloudpickle 0.8.0\n",
      "    Uninstalling cloudpickle-0.8.0:\n",
      "      Successfully uninstalled cloudpickle-0.8.0\n",
      "Successfully installed cloudpickle-1.6.0 gym-0.18.3 pyglet-1.5.15\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spyder 3.3.3 has requirement pyqt5<=5.12; python_version >= \"3\", but you'll have pyqt5 5.14.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "#installing dependencies\n",
    "pip install gym\n",
    "pip install torch\n",
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d81eca809463>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode, **kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'human'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\gym\\envs\\classic_control\\cartpole.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_rotation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'rgb_array'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, return_rgb_array)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monetime_geoms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_rgb_array\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pyglet\\window\\win32\\__init__.py\u001b[0m in \u001b[0;36mflip\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    354\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_always_dwm\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dwm_composition_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interval\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m                     \u001b[0m_dwmapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDwmFlush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Gym environment\n",
    "import gym\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "\n",
    "for _ in range(1000):\n",
    "    env.render()\n",
    "    env.step(env.action_space.sample())\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import functools\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IPython's display module is imported to aid us in plotting images to the screen later.\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython: from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define a neural net that will act as target and policy net. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target and policy net\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, img_height, img_width):\n",
    "        super().__init__()\n",
    "\n",
    "        input_dim=(3,img_height,img_width)\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(in_channels=6, out_channels=10, kernel_size=3, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        num_features_before_fcnn = functools.reduce(operator.mul, list(self.feature_extractor(torch.rand(1, *input_dim)).shape))\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=num_features_before_fcnn, out_features=32),\n",
    "            nn.Linear(in_features=32, out_features=2),\n",
    "        )\n",
    "\n",
    "        \n",
    "    def forward(self, t):\n",
    "        batch_size = t.size(0)\n",
    "\n",
    "        out = self.feature_extractor(t)\n",
    "        out = out.view(batch_size, -1)  # flatten the vector\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiences from replay memory is what we'll use to train our network. To create experiences, we creating a class called Experience. This class will be used to create instances of Experience objects that will get stored in and sampled from replay memory later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiences \n",
    "Experience = namedtuple(\n",
    "    'Experience',\n",
    "    ('state', 'action', 'next_state', 'reward')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReplayMemory class is where these experiences will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ReplayMemory class \n",
    "class ReplayMemory():\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.push_count = 0\n",
    "    def push(self, experience):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(experience)\n",
    "        else:\n",
    "            self.memory[self.push_count % self.capacity] = experience\n",
    "        self.push_count += 1\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    def can_provide_sample(self, batch_size):\n",
    "        return len(self.memory) >= batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a balance of exploration and exploitation, we use an epsilon greedy strategy. With this strategy, we define an exploration rate called epsilon that we initially set to . This exploration rate is the probability that our agent will explore the environment rather than exploit it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EpsilonGreedyStrategy\n",
    "class EpsilonGreedyStrategy():\n",
    "    def __init__(self, start, end, decay):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.decay = decay\n",
    "    def get_exploration_rate(self, current_step):\n",
    "        return self.end + (self.start - self.end) * \\\n",
    "        math.exp(-1. * current_step * self.decay)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speaking of our agent, an Agent class is where we're headed next. Our Agent class will require a strategy and num_actions.\n",
    "\n",
    "So, later when we create an Agent object, we'll need to already have an instance of EpsilonGreedyStrategy class created so that we can use that strategy to create our agent. num_actions corresponds to how many possible actions can the agent take from a given state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Agent():\n",
    "    def __init__(self, strategy, num_actions, device):\n",
    "        self.current_step = 0\n",
    "        self.strategy = strategy\n",
    "        self.num_actions = num_actions\n",
    "        self.device = device\n",
    "    def select_action(self, state, policy_net, device):\n",
    "        rate = self.strategy.get_exploration_rate(self.current_step)\n",
    "        self.current_step += 1\n",
    "        if rate > random.random():\n",
    "            action = random.randrange(self.num_actions)\n",
    "            return torch.tensor([action]).to(self.device) # explore      \n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                return policy_net(state).argmax(dim=1).to(self.device) # exploit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CartPoleEnvManager class will manage our cart and pole environment. It will wrap several of gym's environment capabilities, and it will also give us some added functionality, like image preprocessing, for the environment images that will be given to our network as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CartPoleEnvManager():\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        self.env = gym.make('CartPole-v0').unwrapped\n",
    "        self.env.reset()\n",
    "        self.current_screen = None\n",
    "        self.done = False\n",
    "    def reset(self):\n",
    "        self.env.reset()\n",
    "        self.current_screen = None\n",
    "    def close(self):\n",
    "        self.env.close()\n",
    "    def render(self, mode='human'):\n",
    "        return self.env.render(mode)\n",
    "    def num_actions_available(self):\n",
    "        return self.env.action_space.n\n",
    "    def take_action(self, action):        \n",
    "        _, reward, self.done, _ = self.env.step(action.item())\n",
    "        return torch.tensor([reward], device=self.device)\n",
    "    def just_starting(self):\n",
    "        return self.current_screen is None\n",
    "    def get_state(self):\n",
    "        if self.just_starting() or self.done:\n",
    "            self.current_screen = self.get_processed_screen()\n",
    "            black_screen = torch.zeros_like(self.current_screen)\n",
    "            return black_screen\n",
    "        else:\n",
    "            s1 = self.current_screen\n",
    "            s2 = self.get_processed_screen()\n",
    "            self.current_screen = s2\n",
    "            return s2 - s1\n",
    "    def get_screen_height(self):\n",
    "        screen = self.get_processed_screen()\n",
    "        return screen.shape[2]\n",
    "    def get_screen_width(self):\n",
    "        screen = self.get_processed_screen()\n",
    "        return screen.shape[3]\n",
    "    def get_processed_screen(self):\n",
    "        screen = self.render('rgb_array').transpose((2, 0, 1)) # PyTorch expects CHW\n",
    "        screen = self.crop_screen(screen)\n",
    "        return self.transform_screen_data(screen)\n",
    "    def crop_screen(self, screen):\n",
    "        screen_height = screen.shape[1]\n",
    "        # Strip off top and bottom\n",
    "        top = int(screen_height * 0.4)\n",
    "        bottom = int(screen_height * 0.8)\n",
    "        screen = screen[:, top:bottom, :]\n",
    "        return screen\n",
    "    def transform_screen_data(self, screen):       \n",
    "        # Convert to float, rescale, convert to tensor\n",
    "        screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "        screen = torch.from_numpy(screen)\n",
    "\n",
    "        # Use torchvision package to compose image transforms\n",
    "        resize = T.Compose([\n",
    "            T.ToPILImage()\n",
    "            ,T.Resize((40,90))\n",
    "            ,T.ToTensor()\n",
    "        ])\n",
    "        return resize(screen).unsqueeze(0).to(self.device) # add a batch dimension (BCHW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Printing Non-Processed Screen\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "em = CartPoleEnvManager(device)\n",
    "em.reset()\n",
    "screen = em.render('rgb_array')\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(screen)\n",
    "plt.title('Non-processed screen example')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 40, 90])\n"
     ]
    }
   ],
   "source": [
    "#Printing Processed Screen\n",
    "screen = em.get_processed_screen()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(screen.squeeze(0).permute(1, 2, 0).cpu(), interpolation='none')\n",
    "plt.title('Processed screen example')\n",
    "plt.show()\n",
    "print(screen.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Printing Starting State\n",
    "screen = em.get_state()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(screen.squeeze(0).permute(1, 2, 0).cpu(), interpolation='none')\n",
    "plt.title('Starting state example')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Printing Non-Starting State\n",
    "for i in range(5):\n",
    "    em.take_action(torch.tensor([1]))\n",
    "screen = em.get_state()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(screen.squeeze(0).permute(1, 2, 0).cpu(), interpolation='none')\n",
    "plt.title('Non starting state example')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Printing Ending Starting State\n",
    "em.done = True\n",
    "screen = em.get_state()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(screen.squeeze(0).permute(1, 2, 0).cpu(), interpolation='none')\n",
    "plt.title('Ending state example')\n",
    "plt.show()\n",
    "em.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're creating this function called plot() that accepts values and a moving average period. This plot will plot the duration of each episode, as well as the 100 episode moving average.\n",
    "\n",
    "We'll also want to plot the 100 episode moving average, so we do so by calling the function get_moving_average(), which accepts the moving_average_period and the values for which it will be calculating the moving average from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(values, moving_avg_period):\n",
    "    plt.figure(2)\n",
    "    plt.clf()        \n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(values)\n",
    "    moving_avg = get_moving_average(moving_avg_period, values)\n",
    "    plt.plot(moving_avg)    \n",
    "    plt.pause(0.001)\n",
    "    print(\"Episode\", len(values), \"\\n\", \\\n",
    "        moving_avg_period, \"episode moving avg:\", moving_avg[-1])\n",
    "    if is_ipython: display.clear_output(wait=True)\n",
    "\n",
    "def get_moving_average(period, values):\n",
    "    values = torch.tensor(values, dtype=torch.float)\n",
    "    if len(values) >= period:\n",
    "        moving_avg = values.unfold(dimension=0, size=period, step=1) \\\n",
    "            .mean(dim=1).flatten(start_dim=0)\n",
    "        moving_avg = torch.cat((torch.zeros(period-1), moving_avg))\n",
    "        return moving_avg.numpy()\n",
    "    else:\n",
    "        moving_avg = torch.zeros(len(values))\n",
    "        return moving_avg.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract_tensors is the function that we called to extract all the states, actions, rewards, and next_states into their own tensors from a given batch of experiences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensor Processing\n",
    "def extract_tensors(experiences):\n",
    "    # Convert batch of Experiences to Experience of batches\n",
    "    batch = Experience(*zip(*experiences))\n",
    "\n",
    "    t1 = torch.cat(batch.state)\n",
    "    t2 = torch.cat(batch.action)\n",
    "    t3 = torch.cat(batch.reward)\n",
    "    t4 = torch.cat(batch.next_state)\n",
    "\n",
    "    return (t1,t2,t3,t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QValues is the class that we used to calculate the q-values for the current states using the policy_net, and the next states using the target_net.\n",
    "\n",
    "This class contains two static methods, meaning that we're able to call these methods without creating an instance of the class first. Because we're creating the class in this way, we're setting up its own device since we won't be creating an instance of this class and passing in our device from our main program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QValues():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_current(policy_net, states, actions):\n",
    "        return policy_net(states).gather(dim=1, index=actions.unsqueeze(-1))\n",
    "    \n",
    "    @staticmethod        \n",
    "    def get_next(target_net, next_states):                \n",
    "        final_state_locations = next_states.flatten(start_dim=1) \\\n",
    "            .max(dim=1)[0].eq(0).type(torch.bool)\n",
    "        non_final_state_locations = (final_state_locations == False)\n",
    "        non_final_states = next_states[non_final_state_locations]\n",
    "        batch_size = next_states.shape[0]\n",
    "        values = torch.zeros(batch_size).to(QValues.device)\n",
    "        values[non_final_state_locations] = target_net(non_final_states).max(dim=1)[0].detach()\n",
    "        return values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within our main program, we're first initializing all of our hyperparameters.\n",
    "\n",
    "Now, we'll set up all of the essential objects using the classes we've built in the previous episodes.\n",
    "First though, let's set up our device for PyTorch. This tells PyTorch to use a GPU if it's available, otherwise use the CPU.\n",
    "Now, we set up our environment manager em using the CartPoleEnvManager class, and we pass in the required device. We then set our strategy to be an instance of the EpsilonGreedyStrategy class, and we pass in the required start, end, and decay values for epsilon.\n",
    "We then define an agent using our Agent class and pass in the required strategy, number of actions available, and device. We then initialize memory to be an instance of ReplayMemory and pass in the capacity using memory_size.Now, we define both our policy network and target network by creating two instances of our DQN class and passing in the height and width of the screen to set up the appropriate input shape of the networks. We put these networks on our defined device using PyTorch's to() function.We also put the target_net into eval mode, which tells PyTorch that this network is not in training mode. In other words, this network will only be used for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740\n",
      "7740\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "gamma = 0.90\n",
    "eps_start = 1\n",
    "eps_end = 0.01\n",
    "eps_decay = 0.001\n",
    "target_update = 10\n",
    "memory_size = 100000\n",
    "lr = 0.001\n",
    "num_episodes = 1000\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "em = CartPoleEnvManager(device)\n",
    "strategy = EpsilonGreedyStrategy(eps_start, eps_end, eps_decay)\n",
    "agent = Agent(strategy, em.num_actions_available(), device)\n",
    "memory = ReplayMemory(memory_size)\n",
    "\n",
    "policy_net = DQN(em.get_screen_height(), em.get_screen_width()).to(device)\n",
    "target_net = DQN(em.get_screen_height(), em.get_screen_width()).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.Adam(params=policy_net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps that we'll be covering now in our main training loop:\n",
    "\n",
    "1 Initialize replay memory capacity.\n",
    "\n",
    "2 Initialize the policy network with random weights.\n",
    "\n",
    "3 Clone the policy network, and call it the target network.\n",
    "\n",
    "4 For each episode:\n",
    "\n",
    "    1 Initialize the starting state.\n",
    "    \n",
    "    2 For each time step:\n",
    "\n",
    "        1 Select an action.\n",
    "        \n",
    "            >>Via exploration or exploitation\n",
    "            \n",
    "        2 Execute selected action in an emulator.\n",
    "        \n",
    "        3 Observe reward and next state.\n",
    "        \n",
    "        4 Store experience in replay memory.\n",
    "        \n",
    "        5 Sample random batch from replay memory.\n",
    "        \n",
    "        6 Preprocess states from batch.\n",
    "        \n",
    "        7 Pass batch of preprocessed states to policy network.\n",
    "        \n",
    "        8 Calculate loss between output Q-values and target Q-values.\n",
    "        \n",
    "            >>Requires a pass to the target network for the next state\n",
    "            \n",
    "        Gradient descent updates weights in the policy network to minimize loss.\n",
    "\n",
    "            >>After  time steps, weights in the target network are updated to the weights in the policy network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-fc9533358617>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0mcurrent_q_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mQValues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_current\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolicy_net\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0mnext_q_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mQValues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_net\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mtarget_q_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnext_q_values\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-0acc3da07fc4>\u001b[0m in \u001b[0;36mget_current\u001b[1;34m(policy_net, states, actions)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_current\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolicy_net\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpolicy_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-95e516ef9ad0>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, t)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# flatten the vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[1;32m--> 396\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training Loop\n",
    "episode_durations = []\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    em.reset()\n",
    "    state = em.get_state()\n",
    "    \n",
    "    for timestep in count():\n",
    "        action = agent.select_action(state, policy_net,device)\n",
    "        reward = em.take_action(action)\n",
    "        next_state = em.get_state()\n",
    "        memory.push(Experience(state, action, next_state, reward))\n",
    "        state = next_state\n",
    "        \n",
    "        if memory.can_provide_sample(batch_size):\n",
    "            experiences = memory.sample(batch_size)\n",
    "            states, actions, rewards, next_states = extract_tensors(experiences)\n",
    "\n",
    "            current_q_values = QValues.get_current(policy_net, states, actions)\n",
    "            next_q_values = QValues.get_next(target_net, next_states)\n",
    "            target_q_values = (next_q_values * gamma) + rewards\n",
    "\n",
    "            loss = F.mse_loss(current_q_values, target_q_values.unsqueeze(1))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        if em.done:\n",
    "            episode_durations.append(timestep)\n",
    "            plot(episode_durations, 100)\n",
    "            break\n",
    "            \n",
    "    if episode % target_update == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "em.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
